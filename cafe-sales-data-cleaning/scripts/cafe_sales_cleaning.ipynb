{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4de3644",
   "metadata": {},
   "source": [
    "# Cafe Sales Data Cleaning\n",
    "\n",
    "**Goal:** Clean and prepare raw cafe POS data for downstream profitability and sales behavior analysis.  \n",
    "**Data:** Raw transaction dataset with missing values, duplicates, and inconsistent categories.  \n",
    "\n",
    "**Steps:**\n",
    "1) Load raw dataset  \n",
    "2) Inspect data (shape, schema, missing values)  \n",
    "3) Clean invalid and missing values \n",
    "4) Standardize data types (dates, numeric fields, categoricals)  \n",
    "5) Business-rule repairs & quality checks \n",
    "6) Final Validation & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.457294Z",
     "start_time": "2025-05-19T00:13:32.221245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317094f",
   "metadata": {},
   "source": [
    "## Step 1: Load raw dataset\n",
    "*Purpose:* Read source CSV and set basic options (encoding, dtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9c7b36d4999b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.469062Z",
     "start_time": "2025-05-19T00:13:32.458820Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/raw_cafe_sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686840287d5cd0a",
   "metadata": {},
   "source": [
    "## Step 2: Inspect data\n",
    "*Purpose:* Understand dataset size, schema, and missing values before applying cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1043c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transaction ID         0\n",
       "Item                 333\n",
       "Quantity             138\n",
       "Price Per Unit       179\n",
       "Total Spent          173\n",
       "Payment Method      2579\n",
       "Location            3265\n",
       "Transaction Date     159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect dataset dimensions\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Preview sample rows\n",
    "df.head(10)\n",
    "\n",
    "# Check schema and dtypes\n",
    "df.info()\n",
    "\n",
    "# Check missing values by column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d42e4c",
   "metadata": {},
   "source": [
    "✅ Inspection results:\n",
    "- Shape: 10000 rows × 8 columns  \n",
    "- Columns: `Transaction ID`, `Item`, `Quantity`, `Price Per Unit`, `Total Spent`, `Payment Method`, `Location`, `Transaction Date`\n",
    "- Notable missing values:\n",
    "    - Item:                 333\n",
    "    - Quantity:             138\n",
    "    - Price Per Unit:       179\n",
    "    - Total Spent:          173\n",
    "    - Payment Method:      2579\n",
    "    - Location:            3265\n",
    "    - Transaction Date:     159\n",
    "- The schema includes **numeric**, **categorical**, and **datetime** fields, but they are all represented as **objects**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f0278",
   "metadata": {},
   "source": [
    "## Step 3: Clean invalid and missing values\n",
    "*Purpose:* Remove duplicates, convert placeholder errors to NaN, and assess missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ff68ec77f9da82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.512434Z",
     "start_time": "2025-05-19T00:13:32.504749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID         0\n",
       "Item                 969\n",
       "Quantity             479\n",
       "Price Per Unit       533\n",
       "Total Spent          502\n",
       "Payment Method      3178\n",
       "Location            3961\n",
       "Transaction Date     460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates if any\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Replace all 'ERROR' and 'UNKNOWN' across the entire DataFrame to nan\n",
    "df = df.replace(['ERROR', 'UNKNOWN'], np.nan)\n",
    "\n",
    "# Check missing values again\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aae171",
   "metadata": {},
   "source": [
    "✅ Cleaning done:\n",
    "- Removed duplicates (if any).  \n",
    "- Standardized placeholder values ('ERROR', 'UNKNOWN') as NaN.  \n",
    "- Missing value counts **increased** because invalid entries were converted to NaN — this is expected and ensures data integrity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3cec57b5fb06a",
   "metadata": {},
   "source": [
    "## Step 4: Standardize data types\n",
    "*Purpose:* Convert columns to appropriate data types for reliable calculations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e81dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    10000 non-null  object        \n",
      " 1   Item              9031 non-null   object        \n",
      " 2   Quantity          9521 non-null   float64       \n",
      " 3   Price Per Unit    9467 non-null   float64       \n",
      " 4   Total Spent       9498 non-null   float64       \n",
      " 5   Payment Method    6822 non-null   object        \n",
      " 6   Location          6039 non-null   object        \n",
      " 7   Transaction Date  9540 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 703.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean categorical columns: strip whitespace if any\n",
    "for col in ['Item', 'Payment Method', 'Location']:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Convert numeric columns\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "df[['Price Per Unit', 'Total Spent']] = df[['Price Per Unit', 'Total Spent']].astype('float64')\n",
    "\n",
    "# Convert date column\n",
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "\n",
    "# Check schema\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e941587",
   "metadata": {},
   "source": [
    "✅ Data types standardized:\n",
    "- Stripped whitespace in categorical fields (`Item`, `Payment Method`, `Location`).  \n",
    "- `Quantity` converted to **integer**, `Price Per Unit` and `Total Spent` to **float**.  \n",
    "- `Transaction Date` parsed as **datetime**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098446300415e01",
   "metadata": {},
   "source": [
    "## Step 5: Business-rule repairs & quality checks\n",
    "*Purpose:* Column-by-column fixes based on simple domain rules: review categories, impute missing values from empirical distributions, and infer `Item` from unit price when possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b877b62",
   "metadata": {},
   "source": [
    "### 5.1: Typo checks for **categorical** columns\n",
    "Quick review on categorical columns (`Item`,`Payment Method`, and `Location`) to catch spelling/case/whitespace issues before any imputation or inference.  \n",
    "**Review only**. No modification here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b18b851495941ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.781091Z",
     "start_time": "2025-05-19T00:13:32.777887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Juice       1171\n",
       "Coffee      1165\n",
       "Salad       1148\n",
       "Cake        1139\n",
       "Sandwich    1131\n",
       "Smoothie    1096\n",
       "Cookie      1092\n",
       "Tea         1089\n",
       "Name: Item, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 'Item', 'Payment Method', and 'Location' for misspelling\n",
    "df['Item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8867d6ca67762a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.827755Z",
     "start_time": "2025-05-19T00:13:32.824398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital Wallet    2291\n",
       "Credit Card       2273\n",
       "Cash              2258\n",
       "Name: Payment Method, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Payment Method'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96623cf919a56cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.869214Z",
     "start_time": "2025-05-19T00:13:32.866339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Takeaway    3022\n",
       "In-store    3017\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b2e5bec412bf0",
   "metadata": {},
   "source": [
    "✅ Observation: No obvious typos found in `Item`, `Payment Method` and `Location`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3588a6",
   "metadata": {},
   "source": [
    "### 5.2 Filling `Item` — infer from `Price Per Unit`\n",
    "If unit price uniquely identifies an item, fill missing `Item` using a price → item mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09f031ab88baec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.898304Z",
     "start_time": "2025-05-19T00:13:32.894267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item\n",
       "Cake        [3.0, nan]\n",
       "Coffee      [2.0, nan]\n",
       "Cookie      [1.0, nan]\n",
       "Juice       [3.0, nan]\n",
       "Salad       [5.0, nan]\n",
       "Sandwich    [4.0, nan]\n",
       "Smoothie    [4.0, nan]\n",
       "Tea         [1.5, nan]\n",
       "Name: Price Per Unit, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check price spread per item to catch mislabeled entries \n",
    "# and for next step of inferring missing 'Item'\n",
    "df.groupby('Item')['Price Per Unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14934cdd7e11f112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:32.943156Z",
     "start_time": "2025-05-19T00:13:32.941450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coffee      1284\n",
       "Salad       1270\n",
       "Cookie      1209\n",
       "Tea         1199\n",
       "Juice       1171\n",
       "Cake        1139\n",
       "Sandwich    1131\n",
       "Smoothie    1096\n",
       "Name: Item, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from unique prices to corresponding products\n",
    "price_to_item = {\n",
    "    1.0: 'Cookie',\n",
    "    1.5: 'Tea',\n",
    "    2.0: 'Coffee',\n",
    "    5.0: 'Salad'\n",
    "}\n",
    "\n",
    "# fill in the 'Item' value\n",
    "mask = df['Item'].isna() & df['Price Per Unit'].isin(price_to_item.keys())\n",
    "df.loc[mask, 'Item'] = df.loc[mask, 'Price Per Unit'].map(price_to_item)\n",
    "\n",
    "# check how much been filled\n",
    "df['Item'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb8cae0ccefcd7",
   "metadata": {},
   "source": [
    "✅ `Item` column filled where unit price provided a unique mapping. Remaining nulls will be filled in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa2ea6b26cff36",
   "metadata": {},
   "source": [
    "### 5.3 Filling `Quantity`, `Price Per Unit`, and `Total Spent`\n",
    "The counts of missing values in these three columns differ.  \n",
    "When two values are present, the third can be derived to complete the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d41ac667bd0cdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.039533Z",
     "start_time": "2025-05-19T00:13:33.003919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill Total Spent = Quantity * Price Per Unit\n",
    "mask_ts = df['Total Spent'].isna() & df['Quantity'].notna() & df['Price Per Unit'].notna()\n",
    "df.loc[mask_ts, 'Total Spent'] = (df.loc[mask_ts, 'Quantity'] * df.loc[mask_ts, 'Price Per Unit']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e83b839dfc773975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.076863Z",
     "start_time": "2025-05-19T00:13:33.040304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill Quantity = Total Spent / Price Per Unit\n",
    "mask_q = df['Quantity'].isna() & df['Total Spent'].notna() & df['Price Per Unit'].notna()\n",
    "df.loc[mask_q, 'Quantity'] = (df.loc[mask_q, 'Total Spent'] / df.loc[mask_q, 'Price Per Unit']).round()\n",
    "# Keep nullable integer for missing-friendly arithmetic\n",
    "df['Quantity'] = df['Quantity'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59b411c224ffa244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.135735Z",
     "start_time": "2025-05-19T00:13:33.078356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item              501\n",
       "Quantity           38\n",
       "Price Per Unit     38\n",
       "Total Spent        40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill Price Per Unit = Total Spent / Quantity\n",
    "mask_ppu = df['Price Per Unit'].isna() & df['Total Spent'].notna() & df['Quantity'].notna()\n",
    "df.loc[mask_ppu, 'Price Per Unit'] = (df.loc[mask_ppu, 'Total Spent'] / df.loc[mask_ppu, 'Quantity']).round(2)\n",
    "\n",
    "# Quick check after the trio fill\n",
    "df[['Item','Quantity','Price Per Unit','Total Spent']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b79c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item filled from price: 495\n"
     ]
    }
   ],
   "source": [
    "# price -> most common item mapping\n",
    "def mode_or_nan(s):\n",
    "    m = s.dropna().mode()\n",
    "    return m.iloc[0] if len(m) else np.nan\n",
    "\n",
    "price_to_item = df.groupby('Price Per Unit')['Item'].apply(mode_or_nan)\n",
    "\n",
    "mask_item = df['Item'].isna() & df['Price Per Unit'].notna()\n",
    "filled_before = int(df['Item'].isna().sum())\n",
    "df.loc[mask_item, 'Item'] = df.loc[mask_item, 'Price Per Unit'].map(price_to_item)\n",
    "filled_after = int(df['Item'].isna().sum())\n",
    "print(f\"Item filled from price: {filled_before - filled_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90bce6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the remaining unidentified items to 'UNKNOWN' since they cannot be determined. \n",
    "df['Item'] = df['Item'].fillna('UNKNOWN')\n",
    "\n",
    "# Drop rows with missing values in these columns, as only a small number remain.\n",
    "df.dropna(subset=['Quantity','Price Per Unit','Total Spent'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f15bac",
   "metadata": {},
   "source": [
    "✅ Filling complete:\n",
    "- Completed `Quantity`, `Price Per Unit`, and `Total Spent` using mutual derivation (triangle relationship).  \n",
    "- Imputed `Item` values from price→item mapping (495 rows filled).  \n",
    "- Assigned **UNKNOWN** to remaining items and dropped unrecoverable rows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c387610172aebcb",
   "metadata": {},
   "source": [
    "### 5.4 Filling `Payment Method`\n",
    "Impute missing values by sampling from the observed distribution to preserve class proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb0ef9fd1e5c6309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.153483Z",
     "start_time": "2025-05-19T00:13:33.149456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filling:\n",
      " NaN               3158\n",
      "Digital Wallet    2280\n",
      "Credit Card       2260\n",
      "Cash              2244\n",
      "Name: Payment Method, dtype: int64\n",
      "\n",
      "===========================\n",
      "\n",
      "After filling:\n",
      " Digital Wallet    3357\n",
      "Credit Card       3303\n",
      "Cash              3282\n",
      "Name: Payment Method, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before filling:\\n\", df['Payment Method'].value_counts(dropna=False))\n",
    "\n",
    "# Distribution of observed categories\n",
    "pm_dist = df['Payment Method'].value_counts(normalize=True, dropna=True)\n",
    "\n",
    "# Mask missing\n",
    "mask_pm = df['Payment Method'].isna()\n",
    "\n",
    "# Fill missing by sampling\n",
    "rng = np.random.default_rng(42)\n",
    "df.loc[mask_pm, 'Payment Method'] = rng.choice(\n",
    "    pm_dist.index,\n",
    "    size=mask_pm.sum(),\n",
    "    p=pm_dist.values\n",
    ")\n",
    "\n",
    "print(\"\\n===========================\\n\")\n",
    "print(\"After filling:\\n\", df['Payment Method'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b94e8",
   "metadata": {},
   "source": [
    "✅ Filling `Payment Method` completed:  \n",
    "- 3,178 missing values were filled using random sampling from the observed distribution.  \n",
    "- Final counts are balanced across methods: **Digital Wallet (3,374)**, **Credit Card (3,319)**, **Cash (3,307)**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb3257",
   "metadata": {},
   "source": [
    "### 5.5 Filling `Location`\n",
    "Impute missing locations using the empirical distribution so the branch mix is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11f2909b73f3a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.157793Z",
     "start_time": "2025-05-19T00:13:33.153993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filling:\n",
      " NaN         3940\n",
      "Takeaway    3004\n",
      "In-store    2998\n",
      "Name: Location, dtype: int64\n",
      "\n",
      "===========================\n",
      "\n",
      "After filling:\n",
      " Takeaway    4985\n",
      "In-store    4957\n",
      "Name: Location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before filling:\\n\", df['Location'].value_counts(dropna=False))\n",
    "\n",
    "# Distribution of observed categories\n",
    "loc_dist = df['Location'].value_counts(normalize=True, dropna=True)\n",
    "\n",
    "# Mask missing\n",
    "mask_loc = df['Location'].isna()\n",
    "\n",
    "# Fill missing by sampling\n",
    "rng = np.random.default_rng(42)\n",
    "df.loc[mask_loc, 'Location'] = rng.choice(\n",
    "    loc_dist.index,\n",
    "    size=mask_loc.sum(),\n",
    "    p=loc_dist.values\n",
    ")\n",
    "\n",
    "print(\"\\n===========================\\n\")\n",
    "print(\"After filling:\\n\", df['Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9643e5",
   "metadata": {},
   "source": [
    "✅ Filling `Location` completed:  \n",
    "- 3,961 missing values were imputed using random sampling from the observed distribution.  \n",
    "- Final counts are balanced across categories: **Takeaway (5,015)**, **In-store (4,985)**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199ff71",
   "metadata": {},
   "source": [
    "### 5.6 Handling `Transaction Date`\n",
    "Standardize the transaction date column for temporal analysis (`NaT` for invalid values).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab18d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing — Transaction Date: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure datetime (in case earlier steps introduced strings)\n",
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "\n",
    "# Fill missing Transaction Date with 'UNKNOWN'\n",
    "df['Transaction Date'] = df['Transaction Date'].fillna('UNKNOWN')\n",
    "\n",
    "# Quick check\n",
    "print(\"Missing — Transaction Date:\", int(df['Transaction Date'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d68a31",
   "metadata": {},
   "source": [
    "✅ Transaction Date cleaned:\n",
    "- Parsed into proper `datetime` format (invalid entries coerced to NaT).  \n",
    "- Extracted `Year`, `Month`, `Day` as numeric fields for grouping and analysis.  \n",
    "- Remaining nulls filled with `\"UNKNOWN\"`, ensuring no missing values.  \n",
    "\n",
    "This keeps both a usable datetime column and structured components for flexible analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682899dd8b73b67",
   "metadata": {},
   "source": [
    "## Step 6: Final Validation & Export\n",
    "\n",
    "*Purpose:* Verify the integrity of the cleaned dataset and prepare it for downstream analysis.\n",
    "\n",
    "- Checked final dataset shape (rows × columns).  \n",
    "- Confirmed that no missing values remain.  \n",
    "- Validated standardized data types across all fields.  \n",
    "- Reviewed summary statistics to ensure data consistency.  \n",
    "- Exported the cleansed dataset (`cleansed_cafe_sales.csv`) for profitability and sales behavior analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7dd2196387dc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.191930Z",
     "start_time": "2025-05-19T00:13:33.190089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9942, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check final dataset shape (rows × columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f84beaa3f3052e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.233089Z",
     "start_time": "2025-05-19T00:13:33.227254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID      0\n",
       "Item                0\n",
       "Quantity            0\n",
       "Price Per Unit      0\n",
       "Total Spent         0\n",
       "Payment Method      0\n",
       "Location            0\n",
       "Transaction Date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify no missing values remain\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f70589027dca0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.274768Z",
     "start_time": "2025-05-19T00:13:33.270612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID       object\n",
       "Item                 object\n",
       "Quantity              Int64\n",
       "Price Per Unit      float64\n",
       "Total Spent         float64\n",
       "Payment Method       object\n",
       "Location             object\n",
       "Transaction Date     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm data types are standardized\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb1edfda75d0b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.388035Z",
     "start_time": "2025-05-19T00:13:33.370794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9942</td>\n",
       "      <td>9942</td>\n",
       "      <td>9942.000000</td>\n",
       "      <td>9942.000000</td>\n",
       "      <td>9942.000000</td>\n",
       "      <td>9942</td>\n",
       "      <td>9942</td>\n",
       "      <td>9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9942</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Juice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3357</td>\n",
       "      <td>4985</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.025749</td>\n",
       "      <td>2.947848</td>\n",
       "      <td>8.931855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.420438</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>6.002356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction ID   Item     Quantity  Price Per Unit  Total Spent  \\\n",
       "count            9942   9942  9942.000000     9942.000000  9942.000000   \n",
       "unique           9942      8          NaN             NaN          NaN   \n",
       "top       TXN_1961373  Juice          NaN             NaN          NaN   \n",
       "freq                1   1414          NaN             NaN          NaN   \n",
       "mean              NaN    NaN     3.025749        2.947848     8.931855   \n",
       "std               NaN    NaN     1.420438        1.279897     6.002356   \n",
       "min               NaN    NaN     1.000000        1.000000     1.000000   \n",
       "25%               NaN    NaN     2.000000        2.000000     4.000000   \n",
       "50%               NaN    NaN     3.000000        3.000000     8.000000   \n",
       "75%               NaN    NaN     4.000000        4.000000    12.000000   \n",
       "max               NaN    NaN     5.000000        5.000000    25.000000   \n",
       "\n",
       "        Payment Method  Location Transaction Date  \n",
       "count             9942      9942             9942  \n",
       "unique               3         2              366  \n",
       "top     Digital Wallet  Takeaway          UNKNOWN  \n",
       "freq              3357      4985              457  \n",
       "mean               NaN       NaN              NaN  \n",
       "std                NaN       NaN              NaN  \n",
       "min                NaN       NaN              NaN  \n",
       "25%                NaN       NaN              NaN  \n",
       "50%                NaN       NaN              NaN  \n",
       "75%                NaN       NaN              NaN  \n",
       "max                NaN       NaN              NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review summary statistics for all columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838a75e",
   "metadata": {},
   "source": [
    "✅ The dataset is now fully prepared for further analytical modeling and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11538d3879c75926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T00:13:33.531171Z",
     "start_time": "2025-05-19T00:13:33.501502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the cleaned dataset for further analysis\n",
    "df.to_csv('cleansed_cafe_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d8ec2",
   "metadata": {},
   "source": [
    "## Final Notes\n",
    "\n",
    "The cleaned dataset (`cleansed_cafe_sales.csv`) is now ready for profitability and sales behavior analysis.  \n",
    "Key improvements include:\n",
    "\n",
    "- Removed duplicates and handled missing values.  \n",
    "- Standardized data types and categorical fields.  \n",
    "- Imputed critical fields (`Quantity`, `Price Per Unit`, `Total Spent`, `Item`, `Payment Method`, `Location`, `Transaction Date`).  \n",
    "- Added derived features such as `Year`, `Month`, and `Day` for temporal analysis.  \n",
    "- Verified final dataset shape, dtypes, and summary statistics.  \n",
    "- Exported the cleansed dataset for downstream use.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
